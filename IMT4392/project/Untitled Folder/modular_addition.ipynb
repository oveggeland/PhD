{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "623ef857",
   "metadata": {},
   "source": [
    "# Reproduction of grokking on modular addition problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8685b927",
   "metadata": {},
   "source": [
    "## Step 1: Produce dataset\n",
    "I start by producing a simple algorithmic dataset, similar to the one in the core paper. The network will be trained to evaluate an expression of the type (a + b) mod p, where a and b are numbered inputs and p is a prime number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db4bc4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import random\n",
    "import einops\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe0ba583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset params\n",
    "p = 97\n",
    "frac_train = 0.3\n",
    "\n",
    "# Create a randomly shuffled list of all possible combinations of input numbers: (i+j) % p = ?\n",
    "pairs = [(i, j, p) for i in range(p) for j in range(p)]\n",
    "random.seed(seed)\n",
    "random.shuffle(pairs)\n",
    "\n",
    "# Divide list into train and validation sets\n",
    "div = int(frac_train*len(pairs))\n",
    "train_set, val_set = pairs[:div], pairs[div:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2dbf78",
   "metadata": {},
   "source": [
    "## Step 2: Define model (2L decoder only transformer)\n",
    "Using NEEL NANDAS (INTERPRETABILITY) as inspiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "153d8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper class to get access to intermediate activations (inspired by Garcon)\n",
    "# It's a dummy module that is the identity function by default\n",
    "# I can wrap any intermediate activation in a HookPoint and get a convenient \n",
    "# way to add PyTorch hooks\n",
    "class HookPoint(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fwd_hooks = []\n",
    "        self.bwd_hooks = []\n",
    "    \n",
    "    def give_name(self, name):\n",
    "        # Called by the model at initialisation\n",
    "        self.name = name\n",
    "    \n",
    "    def add_hook(self, hook, dir='fwd'):\n",
    "        # Hook format is fn(activation, hook_name)\n",
    "        # Change it into PyTorch hook format (this includes input and output, \n",
    "        # which are the same for a HookPoint)\n",
    "        def full_hook(module, module_input, module_output):\n",
    "            return hook(module_output, name=self.name)\n",
    "        if dir=='fwd':\n",
    "            handle = self.register_forward_hook(full_hook)\n",
    "            self.fwd_hooks.append(handle)\n",
    "        elif dir=='bwd':\n",
    "            handle = self.register_backward_hook(full_hook)\n",
    "            self.bwd_hooks.append(handle)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid direction {dir}\")\n",
    "    \n",
    "    def remove_hooks(self, dir='fwd'):\n",
    "        if (dir=='fwd') or (dir=='both'):\n",
    "            for hook in self.fwd_hooks:\n",
    "                hook.remove()\n",
    "            self.fwd_hooks = []\n",
    "        if (dir=='bwd') or (dir=='both'):\n",
    "            for hook in self.bwd_hooks:\n",
    "                hook.remove()\n",
    "            self.bwd_hooks = []\n",
    "        if dir not in ['fwd', 'bwd', 'both']:\n",
    "            raise ValueError(f\"Invalid direction {dir}\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57ee0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network architecture\n",
    "# I defined my own transformer from scratch so I'd fully understand each component \n",
    "# - I expect this wasn't necessary or particularly important, and a bunch of this \n",
    "# replicates existing PyTorch functionality\n",
    "\n",
    "# Embed & Unembed\n",
    "class Embed(nn.Module):\n",
    "    def __init__(self, d_vocab, d_model):\n",
    "        super().__init__()\n",
    "        self.W_E = nn.Parameter(torch.randn(d_model, d_vocab)/np.sqrt(d_model))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.einsum('dbp -> bpd', self.W_E[:, x])\n",
    "\n",
    "class Unembed(nn.Module):\n",
    "    def __init__(self, d_vocab, d_model):\n",
    "        super().__init__()\n",
    "        self.W_U = nn.Parameter(torch.randn(d_model, d_vocab)/np.sqrt(d_vocab))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return (x @ self.W_U)\n",
    "\n",
    "# Positional Embeddings\n",
    "class PosEmbed(nn.Module):\n",
    "    def __init__(self, max_ctx, d_model):\n",
    "        super().__init__()\n",
    "        self.W_pos = nn.Parameter(torch.randn(max_ctx, d_model)/np.sqrt(d_model))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x+self.W_pos[:x.shape[-2]]\n",
    "\n",
    "# LayerNorm\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, epsilon = 1e-4, model=[None]):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.w_ln = nn.Parameter(torch.ones(d_model))\n",
    "        self.b_ln = nn.Parameter(torch.zeros(d_model))\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.model[0].use_ln:\n",
    "            x = x - x.mean(axis=-1)[..., None]\n",
    "            x = x / (x.std(axis=-1)[..., None] + self.epsilon)\n",
    "            x = x * self.w_ln\n",
    "            x = x + self.b_ln\n",
    "            return x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "# Attention\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_head, n_ctx, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.W_K = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
    "        self.W_Q = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
    "        self.W_V = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
    "        self.W_O = nn.Parameter(torch.randn(d_model, d_head * num_heads)/np.sqrt(d_model))\n",
    "        self.register_buffer('mask', torch.tril(torch.ones((n_ctx, n_ctx))))\n",
    "        self.d_head = d_head\n",
    "        self.hook_k = HookPoint()\n",
    "        self.hook_q = HookPoint()\n",
    "        self.hook_v = HookPoint()\n",
    "        self.hook_z = HookPoint()\n",
    "        self.hook_attn = HookPoint()\n",
    "        self.hook_attn_pre = HookPoint()\n",
    "\n",
    "    def forward(self, x):\n",
    "        k = self.hook_k(torch.einsum('ihd,bpd->biph', self.W_K, x))\n",
    "        q = self.hook_q(torch.einsum('ihd,bpd->biph', self.W_Q, x))\n",
    "        v = self.hook_v(torch.einsum('ihd,bpd->biph', self.W_V, x))\n",
    "        attn_scores_pre = torch.einsum('biph,biqh->biqp', k, q)\n",
    "        attn_scores_masked = torch.tril(attn_scores_pre) - 1e10 * (1 - self.mask[:x.shape[-2], :x.shape[-2]])\n",
    "        attn_matrix = self.hook_attn(F.softmax(self.hook_attn_pre(attn_scores_masked/np.sqrt(self.d_head)), dim=-1))\n",
    "        z = self.hook_z(torch.einsum('biph,biqp->biqh', v, attn_matrix))\n",
    "        z_flat = einops.rearrange(z, 'b i q h -> b q (i h)')\n",
    "        out = torch.einsum('df,bqf->bqd', self.W_O, z_flat)\n",
    "        return out\n",
    "\n",
    "# MLP Layers\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_model, d_mlp, act_type, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.W_in = nn.Parameter(torch.randn(d_mlp, d_model)/np.sqrt(d_model))\n",
    "        self.b_in = nn.Parameter(torch.zeros(d_mlp))\n",
    "        self.W_out = nn.Parameter(torch.randn(d_model, d_mlp)/np.sqrt(d_model))\n",
    "        self.b_out = nn.Parameter(torch.zeros(d_model))\n",
    "        self.act_type = act_type\n",
    "        # self.ln = LayerNorm(d_mlp, model=self.model)\n",
    "        self.hook_pre = HookPoint()\n",
    "        self.hook_post = HookPoint()\n",
    "        assert act_type in ['ReLU', 'GeLU']\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hook_pre(torch.einsum('md,bpd->bpm', self.W_in, x) + self.b_in)\n",
    "        if self.act_type=='ReLU':\n",
    "            x = F.relu(x)\n",
    "        elif self.act_type=='GeLU':\n",
    "            x = F.gelu(x)\n",
    "        x = self.hook_post(x)\n",
    "        x = torch.einsum('dm,bpm->bpd', self.W_out, x) + self.b_out\n",
    "        return x\n",
    "\n",
    "# Transformer Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_mlp, d_head, num_heads, n_ctx, act_type, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        # self.ln1 = LayerNorm(d_model, model=self.model)\n",
    "        self.attn = Attention(d_model, num_heads, d_head, n_ctx, model=self.model)\n",
    "        # self.ln2 = LayerNorm(d_model, model=self.model)\n",
    "        self.mlp = MLP(d_model, d_mlp, act_type, model=self.model)\n",
    "        self.hook_attn_out = HookPoint()\n",
    "        self.hook_mlp_out = HookPoint()\n",
    "        self.hook_resid_pre = HookPoint()\n",
    "        self.hook_resid_mid = HookPoint()\n",
    "        self.hook_resid_post = HookPoint()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hook_resid_mid(x + self.hook_attn_out(self.attn((self.hook_resid_pre(x)))))\n",
    "        x = self.hook_resid_post(x + self.hook_mlp_out(self.mlp((x))))\n",
    "        return x\n",
    "\n",
    "# Full transformer\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_layers, d_vocab, d_model, d_mlp, d_head, num_heads, n_ctx, act_type, use_cache=False, use_ln=True):\n",
    "        super().__init__()\n",
    "        self.cache = {}\n",
    "        self.use_cache = use_cache\n",
    "\n",
    "        self.embed = Embed(d_vocab, d_model)\n",
    "        self.pos_embed = PosEmbed(n_ctx, d_model)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(d_model, d_mlp, d_head, num_heads, n_ctx, act_type, model=[self]) for i in range(num_layers)])\n",
    "        # self.ln = LayerNorm(d_model, model=[self])\n",
    "        self.unembed = Unembed(d_vocab, d_model)\n",
    "        self.use_ln = use_ln\n",
    "\n",
    "        for name, module in self.named_modules():\n",
    "            if type(module)==HookPoint:\n",
    "                module.give_name(name)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.pos_embed(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        # x = self.ln(x)\n",
    "        x = self.unembed(x)\n",
    "        return x\n",
    "\n",
    "    def set_use_cache(self, use_cache):\n",
    "        self.use_cache = use_cache\n",
    "    \n",
    "    def hook_points(self):\n",
    "        return [module for name, module in self.named_modules() if 'hook' in name]\n",
    "\n",
    "    def remove_all_hooks(self):\n",
    "        for hp in self.hook_points():\n",
    "            hp.remove_hooks('fwd')\n",
    "            hp.remove_hooks('bwd')\n",
    "    \n",
    "    def cache_all(self, cache, incl_bwd=False):\n",
    "        # Caches all activations wrapped in a HookPoint\n",
    "        def save_hook(tensor, name):\n",
    "            cache[name] = tensor.detach()\n",
    "        def save_hook_back(tensor, name):\n",
    "            cache[name+'_grad'] = tensor[0].detach()\n",
    "        for hp in self.hook_points():\n",
    "            hp.add_hook(save_hook, 'fwd')\n",
    "            if incl_bwd:\n",
    "                hp.add_hook(save_hook_back, 'bwd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda3b17",
   "metadata": {},
   "source": [
    "## Step 3: Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d42a0183",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "weight_decay = 1.0\n",
    "d_model = 128\n",
    "num_epochs = 50000\n",
    "save_models = False\n",
    "save_every = 100\n",
    "stopping_thresh = -1\n",
    "seed = 0\n",
    "\n",
    "# Model parameters\n",
    "num_layers = 1\n",
    "batch_style = 'full'\n",
    "d_vocab = p+1\n",
    "n_ctx = 3\n",
    "d_mlp = 4*d_model\n",
    "num_heads = 4\n",
    "assert d_model % num_heads == 0, \"Error with parameters\"\n",
    "d_head = d_model//num_heads\n",
    "act_type = 'ReLU' #@param ['ReLU', 'GeLU']\n",
    "use_ln = False\n",
    "random_answers = np.random.randint(low=0, high=p, size=(p, p))\n",
    "fns_dict = {'add': lambda x,y:(x+y)%p, 'subtract': lambda x,y:(x-y)%p, 'x2xyy2':lambda x,y:(x**2+x*y+y**2)%p, 'rand':lambda x,y:random_answers[x][y]}\n",
    "fn = fns_dict[fn_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3f48081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for model training\n",
    "\n",
    "def full_loss(model, data, device):\n",
    "    # Take the final position only\n",
    "    logits = model(data)[:, -1]\n",
    "    labels = torch.tensor([fn(i, j) for i, j, _ in data]).to(device)\n",
    "    return cross_entropy_high_precision(logits, labels)\n",
    "\n",
    "def cross_entropy_high_precision(logits, labels):\n",
    "    # Shapes: batch x vocab, batch\n",
    "    # Cast logits to float64 because log_softmax has a float32 underflow on overly \n",
    "    # confident data and can only return multiples of 1.2e-7 (the smallest float x\n",
    "    # such that 1+x is different from 1 in float32). This leads to loss spikes \n",
    "    # and dodgy gradients\n",
    "    logprobs = F.log_softmax(logits.to(torch.float64), dim=-1)\n",
    "    prediction_logprobs = torch.gather(logprobs, index=labels[:, None], dim=-1)\n",
    "    loss = -torch.mean(prediction_logprobs)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc97725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name grok_1666909175\n",
      "0_1.5599_1.5586\n",
      "100_0.8707_2.0534\n",
      "200_-3.6560_2.8766\n",
      "300_-4.7438_2.9005\n",
      "400_-5.8725_2.9522\n",
      "500_-6.9757_3.0070\n",
      "600_-8.0646_3.0618\n",
      "700_-9.1375_3.1154\n",
      "800_-10.1946_3.1674\n",
      "900_-11.2324_3.2173\n",
      "1000_-12.2308_3.2637\n",
      "1100_-13.1518_3.3048\n",
      "1200_-13.9343_3.3371\n",
      "1300_-14.5117_3.3586\n",
      "1400_-14.8559_3.3683\n",
      "1500_-15.0048_3.3680\n",
      "1600_-15.0472_3.3625\n",
      "1700_-15.0551_3.3550\n",
      "1800_-15.0572_3.3471\n",
      "1900_-15.0595_3.3393\n",
      "2000_-15.0614_3.3312\n",
      "2100_-15.0650_3.3233\n",
      "2200_-15.0688_3.3152\n",
      "2300_-15.0732_3.3072\n",
      "2400_-15.0772_3.2991\n",
      "2500_-15.0824_3.2906\n",
      "2600_-15.0872_3.2819\n",
      "2700_-15.0914_3.2729\n",
      "2800_-15.0961_3.2638\n",
      "2900_-15.1010_3.2549\n",
      "3000_-15.1056_3.2458\n",
      "3100_-15.1096_3.2363\n",
      "3200_-15.1144_3.2264\n",
      "3300_-15.1184_3.2161\n",
      "3400_-15.1232_3.2055\n",
      "3500_-15.1267_3.1945\n",
      "3600_-15.1314_3.1833\n",
      "3700_-15.1361_3.1719\n",
      "3800_-15.1408_3.1596\n",
      "3900_-15.1454_3.1470\n",
      "4000_-15.1502_3.1337\n",
      "4100_-15.1548_3.1198\n",
      "4200_-15.1592_3.1052\n",
      "4300_-15.1647_3.0900\n",
      "4400_-15.1694_3.0739\n",
      "4500_-15.1743_3.0569\n",
      "4600_-15.1777_3.0391\n",
      "4700_-15.1845_3.0203\n",
      "4800_-15.1895_3.0005\n",
      "4900_-15.1957_2.9787\n",
      "5000_-15.2007_2.9556\n",
      "5100_-15.2075_2.9316\n",
      "5200_-15.2121_2.9058\n",
      "5300_-15.2196_2.8779\n",
      "5400_-15.2271_2.8478\n",
      "5500_-15.2341_2.8154\n",
      "5600_-15.2406_2.7808\n",
      "5700_-15.2480_2.7438\n",
      "5800_-15.2576_2.7038\n",
      "5900_-15.2664_2.6597\n",
      "6000_-15.2774_2.6103\n",
      "6100_-15.2885_2.5546\n",
      "6200_-15.3014_2.4924\n",
      "6300_-15.3122_2.4235\n",
      "6400_-15.3249_2.3490\n",
      "6500_-15.3391_2.2660\n",
      "6600_-15.3528_2.1736\n",
      "6700_-15.3688_2.0733\n",
      "6800_-15.3826_1.9656\n",
      "6900_-15.3995_1.8514\n",
      "7000_-15.4147_1.7292\n",
      "7100_-15.4322_1.5977\n",
      "7200_-15.4498_1.4522\n",
      "7300_-15.4704_1.2903\n",
      "7400_-15.4926_1.1119\n",
      "7500_-15.5168_0.9169\n",
      "7600_-15.5435_0.6970\n",
      "7700_-15.5741_0.4461\n",
      "7800_-15.6045_0.1641\n",
      "7900_-15.6442_-0.1550\n",
      "8000_-15.6826_-0.5161\n",
      "8100_-15.7237_-0.9422\n",
      "8200_-15.7666_-1.4269\n",
      "8300_-15.8058_-1.9668\n",
      "8400_-15.8406_-2.5168\n",
      "8500_-15.8686_-3.0601\n",
      "8600_-15.8926_-3.5803\n",
      "8700_-15.9115_-4.0633\n",
      "8800_-15.9260_-4.4952\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Calc gradients and perform backprop\u001b[39;00m\n\u001b[1;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Init model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer(num_layers=num_layers, d_vocab=d_vocab, d_model=d_model, d_mlp=d_mlp, d_head=d_head, num_heads=num_heads, n_ctx=n_ctx, act_type=act_type, use_cache=False, use_ln=use_ln)\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizing process\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay, betas=(0.9, 0.98))\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(step/10, 1))\n",
    "\n",
    "# Run formalities\n",
    "run_name = f\"grok_{int(time.time())}\"\n",
    "print(f'Run name {run_name}')\n",
    "if save_models:\n",
    "    os.mkdir(root/run_name)\n",
    "    save_dict = {'model':model.state_dict(), 'train_data':train, 'test_data':test}\n",
    "    torch.save(save_dict, root/run_name/'init.pth')\n",
    "    \n",
    "# Allocate lists for loss storage\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Train over several epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # Calculate train and test loss\n",
    "    train_loss = full_loss(model, train, device)\n",
    "    train_losses.append(train_loss.item())\n",
    "    \n",
    "    test_loss = full_loss(model, test, device)\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # Print status\n",
    "    if epoch%100 == 0: print(f\"{epoch}_{np.log(train_loss.item()):.4f}_{np.log(test_loss.item()):.4f}\")#_{train_acc.item():.4f}_{test_acc.item():.4f}\")\n",
    "    \n",
    "    # Calc gradients and perform backprop\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if test_loss.item() < stopping_thresh:\n",
    "        break\n",
    "        \n",
    "    if (save_models) and (epoch%save_every == 0):\n",
    "        if test_loss.item() < stopping_thresh:\n",
    "            break\n",
    "        save_dict = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'test_loss': test_loss,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        torch.save(save_dict, root/run_name/f\"{epoch}.pth\")\n",
    "        print(f\"Saved model to {root/run_name/f'{epoch}.pth'}\")\n",
    "        \n",
    "if not save_models:\n",
    "    os.mkdir(root/run_name)\n",
    "save_dict = {\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'scheduler': scheduler.state_dict(),\n",
    "    'train_loss': train_loss,\n",
    "    'test_loss': test_loss,\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses,\n",
    "    'epoch': epoch,\n",
    "}\n",
    "\n",
    "torch.save(save_dict, root/run_name/f\"final.pth\")\n",
    "print(f\"Saved model to {root/run_name/f'final.pth'}\")\n",
    "lines([train_losses, test_losses], labels=['train', 'test'], log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2864a7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe3e404f1f0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b4cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
